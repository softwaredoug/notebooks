{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ff267e-a44b-485c-a7ae-e73e3b3947b2",
   "metadata": {},
   "source": [
    "From shared reference point [proof of concept](http://localhost:8888/lab/tree/vector_search/Shared%20Reference%20Proof%20of%20Concept.ipynb) we saw we got OK'ish recall using a few thousand reference points and querying with 100. We would like to\n",
    "\n",
    "1. Increase number of reference points\n",
    "2. Decrease the number needed at query time\n",
    "\n",
    "In a system that uses this, this setup would increase recall with the least impact to performance.\n",
    "\n",
    "This notebook performs a grid search over the possible values.\n",
    "\n",
    "## Load sentences\n",
    "\n",
    "Reminder we use minilm encoded sentences from wikipedia, sampled down by 50% due to memory constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c057a40-28d4-44fc-a6a7-453514e8a119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3935913, 384), 3935913)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_sentences():\n",
    "    # From\n",
    "    # https://www.kaggle.com/datasets/softwaredoug/wikipedia-sentences-all-minilm-l6-v2\n",
    "    with open('wikisent2_all.npz', 'rb') as f:\n",
    "        wiki_vects = np.load(f)\n",
    "        wiki_vects = vects['arr_0']\n",
    "        # vects = np.stack(vects)\n",
    "        all_normed = (np.linalg.norm(wiki_vects, axis=1) > 0.99) & (np.linalg.norm(wiki_vects, axis=1) < 1.01)\n",
    "        assert all_normed.all(), \"Something is wrong - vectors are not normalized!\"\n",
    "\n",
    "    with open('wikisent2.txt', 'rt') as f:\n",
    "        wiki_sentences = f.readlines()\n",
    "\n",
    "    return wiki_sentences, wiki_vects\n",
    "\n",
    "sentences, vects = load_sentences()\n",
    "\n",
    "# Shrink by 50% for the RAM savings\n",
    "sentences = sentences[::2]\n",
    "vects = vects[::2]\n",
    "vects.shape, len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1297667-7536-4aa2-b4a0-7176f6becbd3",
   "metadata": {},
   "source": [
    "## Build index\n",
    "\n",
    "As per the proof of concept:\n",
    "\n",
    "- Function to generate random vectors\n",
    "- Build index of reference points with dot products back to main vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a0311d2-f207-4d98-bc5e-497c700732d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00666564, -0.0722622 ,  0.0428574 , -0.02779602, -0.01125637,\n",
       "        0.00735623,  0.00019494,  0.03934172, -0.04226361, -0.00964803,\n",
       "        0.05044241,  0.02423316, -0.05395501,  0.02432852, -0.01583304,\n",
       "        0.0223122 , -0.03727536, -0.06231928,  0.02635215, -0.08106241,\n",
       "        0.00476535,  0.02151036,  0.04897824,  0.05952181,  0.06735643,\n",
       "       -0.06717623, -0.04716457, -0.07152112, -0.0193187 ,  0.04654273,\n",
       "       -0.07812368,  0.09264148, -0.0109842 ,  0.00154082,  0.00237992,\n",
       "        0.00701564,  0.09279916,  0.00235389,  0.03603774, -0.01469911,\n",
       "        0.00309564,  0.05114861, -0.01276528,  0.03691551, -0.03083302,\n",
       "       -0.02454237, -0.00770771, -0.01561039,  0.06417661, -0.04109687,\n",
       "       -0.00830815,  0.06693096, -0.06680911, -0.02094927, -0.01184418,\n",
       "        0.07182279,  0.01817778,  0.00846186,  0.00025429,  0.03275067,\n",
       "       -0.05605074, -0.05458292, -0.02311123, -0.01631234, -0.06567901,\n",
       "        0.10800846, -0.00620358,  0.01366184,  0.008013  ,  0.03747595,\n",
       "       -0.04521986,  0.06502654,  0.07844825, -0.06070132,  0.04851783,\n",
       "       -0.0417637 ,  0.03947611, -0.13252151, -0.06051598,  0.00340502,\n",
       "       -0.04595394, -0.00823143, -0.02812147,  0.08225041, -0.02176087,\n",
       "        0.02104117,  0.04690187, -0.02328453, -0.0483951 , -0.07746096,\n",
       "        0.02774937, -0.01016704,  0.03997634, -0.11650776, -0.00959251,\n",
       "        0.01854546,  0.01731111, -0.04568734, -0.03659906,  0.00884995,\n",
       "       -0.06936461, -0.04487484, -0.02041847,  0.04834674, -0.12551732,\n",
       "       -0.00670219,  0.05009386, -0.05232971,  0.09265   , -0.00338461,\n",
       "        0.01452377, -0.00341409,  0.05528282, -0.00861639, -0.02880685,\n",
       "       -0.03406175,  0.02341844,  0.06165666,  0.054441  , -0.02221608,\n",
       "       -0.09189154, -0.02416624, -0.00699077,  0.04082536, -0.00842268,\n",
       "        0.10101044,  0.01289626, -0.0318578 , -0.05365573,  0.06978771,\n",
       "       -0.04121856,  0.01803787, -0.04727205,  0.00015661,  0.02115991,\n",
       "        0.07843212,  0.0167024 , -0.0456776 , -0.07273683,  0.10857586,\n",
       "        0.00215419, -0.06926449,  0.07097973,  0.09076999,  0.0754079 ,\n",
       "       -0.06919797, -0.01600319, -0.00880751, -0.05534298, -0.04274114,\n",
       "        0.02552823,  0.04723625, -0.00652674,  0.04212462, -0.00413426,\n",
       "        0.0475745 , -0.02284802,  0.07402092, -0.04229558,  0.07589543,\n",
       "        0.02438848, -0.07605799, -0.05868066, -0.0474842 , -0.04883619,\n",
       "        0.0155896 ,  0.0133238 ,  0.04436633,  0.00038218,  0.02909169,\n",
       "       -0.0350771 , -0.05567415, -0.06762884, -0.0393625 , -0.00903431,\n",
       "        0.01959579,  0.10437546, -0.05937593,  0.01402925, -0.07624343,\n",
       "       -0.00910832, -0.01920749, -0.07562818,  0.07636667,  0.01716494,\n",
       "       -0.07565339, -0.04200672, -0.02313813, -0.02336593, -0.03102713,\n",
       "        0.07034017, -0.00986284, -0.14569748,  0.00903838,  0.03518671,\n",
       "       -0.01527195,  0.00682656, -0.09843704, -0.03460905,  0.01156491,\n",
       "        0.08373084,  0.09284467,  0.03581822, -0.03224413, -0.0188604 ,\n",
       "       -0.08636736,  0.0066695 ,  0.05773381,  0.01831261, -0.00846076,\n",
       "        0.0263784 , -0.00574331,  0.032208  , -0.06434978,  0.02287886,\n",
       "       -0.02572709, -0.05093023, -0.05743954,  0.07420755,  0.05481724,\n",
       "        0.01282601, -0.13606316, -0.0445739 ,  0.00413906, -0.01737224,\n",
       "        0.06095916,  0.00896471, -0.1010085 , -0.07957011, -0.07415684,\n",
       "       -0.08351955,  0.04764263,  0.00472849, -0.04384135,  0.07478229,\n",
       "        0.07650608,  0.04566598, -0.07700401, -0.08626146,  0.00974176,\n",
       "       -0.03101094, -0.0563766 , -0.03544965, -0.00766611,  0.0034164 ,\n",
       "        0.0399838 , -0.10760831, -0.00762468, -0.0424217 ,  0.02288509,\n",
       "       -0.00457129, -0.09935654, -0.0285135 ,  0.01751236, -0.04839915,\n",
       "        0.008803  , -0.07050128,  0.06458717,  0.02980649,  0.05195095,\n",
       "       -0.06406191,  0.03744589, -0.07213465, -0.00225123, -0.08126393,\n",
       "       -0.01357686,  0.05148496, -0.08692109, -0.06152866,  0.0147101 ,\n",
       "       -0.04260981,  0.03874843,  0.00221444, -0.0867494 ,  0.03890246,\n",
       "        0.04298554,  0.0173816 , -0.07303075,  0.01561183, -0.05460348,\n",
       "       -0.06415809,  0.03428763, -0.03693292, -0.02115266, -0.06171878,\n",
       "        0.06822   ,  0.00273835,  0.06751235, -0.03239212,  0.05115046,\n",
       "        0.0387846 , -0.03947428,  0.05144355, -0.05189414,  0.07635387,\n",
       "       -0.01482325, -0.04675275,  0.01136895,  0.04873355, -0.04315238,\n",
       "       -0.0743479 ,  0.01481672,  0.01093212, -0.03579394, -0.0033367 ,\n",
       "        0.08964215, -0.08796171,  0.04167561,  0.0236097 ,  0.01807866,\n",
       "       -0.01796337,  0.02215244, -0.05888653, -0.0142862 , -0.0152391 ,\n",
       "        0.02592709,  0.00218463,  0.03383017,  0.00128108, -0.03964004,\n",
       "        0.01780367,  0.00909368, -0.05481687, -0.0271252 , -0.06224358,\n",
       "       -0.07373308, -0.04548418,  0.03664046,  0.0405654 ,  0.05872844,\n",
       "       -0.01786302,  0.03522804,  0.00246669, -0.00502923, -0.13172118,\n",
       "        0.02249474, -0.04859684,  0.03379627,  0.02506497,  0.0046033 ,\n",
       "       -0.04699579,  0.0661732 , -0.0005359 , -0.09919242,  0.04500385,\n",
       "        0.01938856,  0.05503738, -0.04385452,  0.07897863, -0.06551415,\n",
       "       -0.00284011, -0.03336215, -0.00968368,  0.04130661, -0.05453694,\n",
       "        0.02344749,  0.00373421, -0.06312115, -0.03012687, -0.01576998,\n",
       "        0.06037194, -0.04467258, -0.00869407, -0.01366831, -0.0733105 ,\n",
       "       -0.05691212, -0.06789914, -0.08595715, -0.08328686,  0.0558967 ,\n",
       "        0.02593704,  0.0453148 ,  0.02804089, -0.03927863,  0.06023752,\n",
       "       -0.10478355, -0.11910912,  0.09632557, -0.07332839,  0.01975935,\n",
       "       -0.06757543,  0.06378789,  0.03813429,  0.01907871])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_vector(num_dims=768):\n",
    "    \"\"\" Sample a unit vector from a sphere in N dimensions.\n",
    "    It's actually important this is gaussian\n",
    "    https://stackoverflow.com/questions/59954810/generate-random-points-on-10-dimensional-unit-sphere\n",
    "    IE Don't do this\n",
    "        projection = np.random.random_sample(size=num_dims)\n",
    "        projection /= np.linalg.norm(projection)\n",
    "    \"\"\"\n",
    "    projection = np.random.normal(size=num_dims)\n",
    "    projection /= np.linalg.norm(projection)\n",
    "    return projection\n",
    "\n",
    "random_vector(num_dims=vects.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ace0a6e-f0cd-4a3a-8e1a-81b5fbba77f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_index(vects, num_refs=1000, refs_factory=random_vector):\n",
    "\n",
    "    refs = np.zeros((num_refs, vects.shape[1]), dtype=np.float32)\n",
    "\n",
    "    for ref_ord in range(0, num_refs):\n",
    "        refs[ref_ord] = refs_factory(num_dims=vects.shape[1])\n",
    "    # Memory gets sucked up here :)\n",
    "    index = np.dot(vects, refs.T)\n",
    "\n",
    "    return refs, index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4db03-f94b-4111-b7df-254bd152556c",
   "metadata": {},
   "source": [
    "## Search ground truth\n",
    "\n",
    "Here's the ground truth for the search, using MiniLM (how the vectors are encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a594249-d77b-4105-9302-3e0f39e2796e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996387 0.700519 \"Mary Had a Little Lamb\", who wrote the novel under the name of Sara J. Hale.\n",
      "\n",
      "1997224 0.6153624 Mary then went into labor.\n",
      "\n",
      "1418816 0.61314523 It begins with the melody of the popular children's song \"Mary Had a Little Lamb\" and then cuts into the main riff, punctuated with a high trumpet trill.\n",
      "\n",
      "1887627 0.5563892 Lamb and is wife, Sara, have one son.\n",
      "\n",
      "775918 0.54064065 For the more domestic and intimate iconic representations of Mary with the infant Jesus on her lap, see Madonna and Child.\n",
      "\n",
      "1393341 0.5362675 In this variant he shows the Christ Child in Mary's lap.\n",
      "\n",
      "611431 0.5288173 Did Jesus Have a Dog?\n",
      "\n",
      "3447108 0.52027595 The songs exclusive to this release are \"Call Me Claus,\" \"Mary Had a Little Lamb,\" and \"'Zat You, Santa Claus?\".\n",
      "\n",
      "2991842 0.5185638 The final two lines detail the former's lamb feast, which resuscitates it.\n",
      "\n",
      "3120137 0.5133202 The \"Lady\" is the Virgin Mary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "query = \"mary had a little lamb\"\n",
    "\n",
    "def search_ground_truth(vects, query, at=10):\n",
    "    query_vector = model.encode(query)\n",
    "    nn = np.dot(vects, query_vector)\n",
    "    top_n = np.argpartition(-nn, at)[:at]\n",
    "    top_n = top_n[nn[top_n].argsort()[::-1]]\n",
    "    return sorted(zip(top_n, nn[top_n]),\n",
    "                  key=lambda scored: scored[1],\n",
    "                  reverse=True)\n",
    "\n",
    "gt_ords = set()\n",
    "for vect_ord, score in search_ground_truth(vects, query):\n",
    "    gt_ords.add(vect_ord)\n",
    "    print(vect_ord, score, sentences[vect_ord])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c193d-2f6e-4dbe-9702-471a49b73f15",
   "metadata": {},
   "source": [
    "## (Inefficient) search function\n",
    "\n",
    "We use the most accurate (though most inefficient) form of the reference point function that gets every vectors dot product to the reference points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a072083d-2db3-4baa-b3ed-f71864c8b2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3935913, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3642364, 0.069736),\n",
       " (3748866, 0.06701364),\n",
       " (554469, 0.0658752),\n",
       " (2430308, 0.065219864),\n",
       " (3253087, 0.06410813),\n",
       " (114717, 0.06364536),\n",
       " (554489, 0.06337762),\n",
       " (146384, 0.063208565),\n",
       " (2934351, 0.06192884),\n",
       " (1606922, 0.061899275)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best_refs(refs, query_vector, num_refs=200):\n",
    "    dotted = np.dot(refs, query_vector)\n",
    "    best_ref_ords = np.argsort(-dotted)[:num_refs]\n",
    "    return best_ref_ords, dotted[best_ref_ords]\n",
    "\n",
    "def search(index, refs, query, num_refs=200):\n",
    "\n",
    "    query_vector = model.encode(query)\n",
    "    \n",
    "    best_ref_ords, dotted = best_refs(refs, query_vector, num_refs=num_refs)\n",
    "    \n",
    "    every_dotted = index[:, best_ref_ords] * dotted\n",
    "    \n",
    "    vects_scored = np.sum(every_dotted, axis=1)\n",
    "    \n",
    "    best_vect_ords = np.argsort(-vects_scored)[:10]\n",
    "    dotted = vects_scored[best_vect_ords]\n",
    "\n",
    "    return list(zip(best_vect_ords, dotted))\n",
    "\n",
    "refs, index = build_index(vects, num_refs=100)\n",
    "search(index, refs, query=\"mary had a litle lamb\", num_refs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be376b-9400-45e6-ac3b-d704f17e3e60",
   "metadata": {},
   "source": [
    "## Search over sample of queries\n",
    "\n",
    "Using a handful of queries lets do a search varying:\n",
    "\n",
    "* `num_query_refs` - the query time refs to score against the query's vector\n",
    "* `num_index_refs` - the number of index time refs to use when constructing the index\n",
    "\n",
    "### Generate ground truths\n",
    "\n",
    "Get a ground truth for each test query to let us compute recall against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c40e077-220e-4fba-8505-99d1cb60335b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "test_queries = [\"what is a cat\", \"where is spain\", \"what is the capital of spain\", \n",
    "\"who framed roger rabbit\", \"free willy\", \"bed bath and beyond\", \"hats and stuff\", \"bed bath beyond\",\n",
    "\"do you even paginate bro?\", \"mary had a little lamb\"]\n",
    "\n",
    "ground_truths = defaultdict(set)\n",
    "for query in test_queries:\n",
    "    for vect_ord, score in search_ground_truth(vects, query):\n",
    "        ground_truths[query].add(vect_ord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e23ac-a3df-40a9-a632-1c51beeb1b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 10 0.19\n",
      "1500 20 0.31\n",
      "1500 30 0.41000000000000003\n",
      "1500 40 0.45\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "def grid_search(refs_factory=random_vector):\n",
    "\n",
    "    num_search_rounds = 10\n",
    "\n",
    "    results = []\n",
    "\n",
    "    search_index_refs = [1500, 1250, 1000, 750, 500, 250]\n",
    "    for num_index_refs in search_index_refs:\n",
    "        refs, index = build_index(vects, num_index_refs,\n",
    "                                  refs_factory=refs_factory)\n",
    "        for num_query_refs in [10, 20, 30, 40, 100, 200]:\n",
    "            test_results = defaultdict(set)\n",
    "\n",
    "            recalls = []\n",
    "            for query in test_queries:\n",
    "                query_search_results = search(index, refs, query, num_refs=num_query_refs)\n",
    "                test_results[query] = set([vect_ord for vect_ord, _ in query_search_results])\n",
    "                intersection = test_results[query] & ground_truths[query]\n",
    "                recalls.append(len(intersection) / 10)\n",
    "\n",
    "            print(num_index_refs, num_query_refs, mean(recalls))\n",
    "            results.append({'num_index_refs': num_index_refs,\n",
    "                            'num_query_refs': num_query_refs,\n",
    "                            'mean': mean(recalls), \n",
    "                            'max': max(recalls),\n",
    "                            'min': min(recalls)})\n",
    "\n",
    "    return results\n",
    "\n",
    "pd.DataFrame(grid_search())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ae088-58cd-4e63-b1ff-07d46c8a6af5",
   "metadata": {},
   "source": [
    "## Try building refs from text outside the index\n",
    "\n",
    "As we sampled every other sentence, what happens when we sample sentences not included in the index as our reference points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26df390e-5f1f-47ff-8750-c9f553d69ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 10 0.0\n",
      "1500 20 0.0\n",
      "1500 30 0.0\n",
      "1500 40 0.0\n",
      "1500 100 0.0\n",
      "1500 200 0.0\n",
      "1250 10 0.0\n",
      "1250 20 0.0\n",
      "1250 30 0.0\n",
      "1250 40 0.0\n",
      "1250 100 0.0\n",
      "1250 200 0.0\n",
      "1000 10 0.0\n",
      "1000 20 0.0\n",
      "1000 30 0.0\n",
      "1000 40 0.0\n",
      "1000 100 0.0\n",
      "1000 200 0.0\n",
      "750 10 0.0\n",
      "750 20 0.0\n",
      "750 30 0.0\n",
      "750 40 0.0\n",
      "750 100 0.0\n",
      "750 200 0.0\n",
      "500 10 0.0\n",
      "500 20 0.0\n",
      "500 30 0.0\n",
      "500 40 0.0\n",
      "500 100 0.0\n",
      "500 200 0.0\n",
      "250 10 0.0\n",
      "250 20 0.0\n",
      "250 30 0.0\n",
      "250 40 0.0\n",
      "250 100 0.0\n",
      "250 200 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'num_index_refs': 1500,\n",
       "  'num_query_refs': 10,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1500,\n",
       "  'num_query_refs': 20,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1500,\n",
       "  'num_query_refs': 30,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1500,\n",
       "  'num_query_refs': 40,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1500,\n",
       "  'num_query_refs': 100,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1500,\n",
       "  'num_query_refs': 200,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1250,\n",
       "  'num_query_refs': 10,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1250,\n",
       "  'num_query_refs': 20,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1250,\n",
       "  'num_query_refs': 30,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1250,\n",
       "  'num_query_refs': 40,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1250,\n",
       "  'num_query_refs': 100,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1250,\n",
       "  'num_query_refs': 200,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1000,\n",
       "  'num_query_refs': 10,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1000,\n",
       "  'num_query_refs': 20,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1000,\n",
       "  'num_query_refs': 30,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1000,\n",
       "  'num_query_refs': 40,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1000,\n",
       "  'num_query_refs': 100,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 1000,\n",
       "  'num_query_refs': 200,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 750,\n",
       "  'num_query_refs': 10,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 750,\n",
       "  'num_query_refs': 20,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 750,\n",
       "  'num_query_refs': 30,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 750,\n",
       "  'num_query_refs': 40,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 750,\n",
       "  'num_query_refs': 100,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 750,\n",
       "  'num_query_refs': 200,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 500,\n",
       "  'num_query_refs': 10,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 500,\n",
       "  'num_query_refs': 20,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 500,\n",
       "  'num_query_refs': 30,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 500,\n",
       "  'num_query_refs': 40,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 500,\n",
       "  'num_query_refs': 100,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 500,\n",
       "  'num_query_refs': 200,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 250,\n",
       "  'num_query_refs': 10,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 250,\n",
       "  'num_query_refs': 20,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 250,\n",
       "  'num_query_refs': 30,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 250,\n",
       "  'num_query_refs': 40,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 250,\n",
       "  'num_query_refs': 100,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0},\n",
       " {'num_index_refs': 250,\n",
       "  'num_query_refs': 200,\n",
       "  'mean': 0.0,\n",
       "  'max': 0.0,\n",
       "  'min': 0.0}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, vects_sample = load_sentences()\n",
    "del _\n",
    "np.random.shuffle(vects_sample)\n",
    "vects_sample = vects_sample[1:20000:2]\n",
    "\n",
    "def vectors_from_text(num_dims):\n",
    "    ref_from_vects = np.random.randint(0, len(vects_sample))\n",
    "    # print(np.array(vects_sample[ref_from_vects]).shape)\n",
    "    return np.array(vects_sample[ref_from_vects])\n",
    "\n",
    "grid_search(refs_factory=vectors_from_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d12de144-4d41-4d88-8134-1d728bb27134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 384)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vects_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3df160-bbad-4595-b035-459c6abe4cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
