{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3e915c-c71b-4bf7-a379-49be6033d6bf",
   "metadata": {},
   "source": [
    "# Vector similarity search through shared reference points\n",
    "\n",
    "It was noted in [this blog post](https://softwaredoug.com/blog/2023/03/02/shared-dot-product.html) that if we know `u.A` and `v.A` we can estimate `u.v`. As an exercise, can we use that to prototype a vector similarity search?\n",
    "\n",
    "## Why would this be useful?\n",
    "\n",
    "* We can compress a large vector space to a much reduced few thousand reference vectors, called `refs` here\n",
    "* We can index a set of vectors, `v`, by noting the most similar vectors to these `refs`, and storing the id and dot product `v.refs`\n",
    "* We might put that index in a traditional index like a search system, and just let traditional text retrieval's similarity work to create cosine similarity between dense vectors\n",
    "\n",
    "## Why would this be not very useful?\n",
    "\n",
    "* We need to arbitrarily partition the space, so the reference points don't induce bias. However this means we are not sensitive to the actual \n",
    "\n",
    "\n",
    "## Import wikipedia sentences and vectors\n",
    "\n",
    "Every 10 sentence of a wikipedia dump of sentences, totalling ~8m sentences/vectors. This is encoded with miniLM\n",
    "\n",
    "```\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    model.encode(sentence)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6894fa-6053-48b9-9de6-3566ad2ead2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7871825, 384)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# All data - quite large for the entire set\n",
    "# can be downlloaded from\n",
    "# https://www.kaggle.com/datasets/softwaredoug/wikipedia-sentences-all-minilm-l6-v2\n",
    "#\n",
    "with open('wikisent2_all.npz', 'rb') as f:\n",
    "    vects = np.load(f)\n",
    "    vects = vects['arr_0']\n",
    "    # vects = np.stack(vects)\n",
    "    all_normed = (np.linalg.norm(vects, axis=1) > 0.99) & (np.linalg.norm(vects, axis=1) < 1.01)\n",
    "    assert all_normed.all(), \"Something is wrong - vectors are not normalized!\"\n",
    "\n",
    "\n",
    "with open('wikisent2.txt', 'rt') as f:\n",
    "    sentences = f.readlines()\n",
    "    \n",
    "    \n",
    "# # Smaller every 10 dataset\n",
    "\n",
    "# with open('wikisent10.npz', 'rb') as f:\n",
    "#     vects = np.load(f)\n",
    "#     vects = np.stack(vects)\n",
    "#     all_normed = (np.linalg.norm(vects, axis=1) > 0.99) & (np.linalg.norm(vects, axis=1) < 1.01)\n",
    "#     assert all_normed.all(), \"Something is wrong - vectors are not normalized!\"\n",
    "\n",
    "# with open('wikisent10.txt', 'rt') as f:\n",
    "#     sentences = f.readlines()\n",
    "    \n",
    "vects.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d6fdd-c252-4977-8215-45a2dbdeee5f",
   "metadata": {},
   "source": [
    "## Ground truth similarity\n",
    "\n",
    "Take a dot product similarity to the query vector as the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404772f4-3e6c-4aa1-bf7c-47725bec3115",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cinnamon Cay is mostly covered with grass and cactus, and is located within the Virgin Islands National Park.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 1000000\n",
    "query_vector = vects[query]\n",
    "query_sentence = sentences[query]\n",
    "query_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b883def0-2c93-4e2d-89ea-1460850d20d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 0.99999994 Cinnamon Cay is mostly covered with grass and cactus, and is located within the Virgin Islands National Park.\n",
      "\n",
      "999999 0.84611005 Cinnamon Cay is a cay in the United States Virgin Islands, situated approximately 0.7 miles east of Trunk Cay in the Cinnamon Bay, and 100 yards from the shore at Cinnamon Bay Beach on Saint John island.\n",
      "\n",
      "999996 0.6374875 Cinnamon Bay is a body of water and a beach on St. John island, within Virgin Islands National Park, in the United States Virgin Islands.\n",
      "\n",
      "6343036 0.6151315 The mess is currently housed in the Cinnamon gardens area of Colombo.\n",
      "\n",
      "5725906 0.5654203 The community was traditionally associated with the cultivation and management of cinnamon and are found mostly in Southern coastal areas of Sri Lanka.\n",
      "\n",
      "3053785 0.5553695 It is found in the Cocos Islands, Moluccas, Lesser Sunda Islands, New Guinea, New Caledonia, Australia and the western Pacific.\n",
      "\n",
      "2891321 0.55075276 It feeds on eucalyptus, especially swamp mahogany, and is found in Victoria, eastern New South Wales, and southeastern Queensland, as well as the capital territory (ACT) around Canberra and on Norfolk Island.\n",
      "\n",
      "3050836 0.54814607 It is found in open forest, woodland, swamps and mangroves in Australia (northern Queensland and north Northern Territory), Indonesia, Papua New Guinea and the Solomon Islands.\n",
      "\n",
      "7543499 0.5409894 Trunk Cay is a small grass-covered islet in Trunk Bay in the United States Virgin Islands.\n",
      "\n",
      "2844650 0.54036677 It can be found within savanna and grassland biomes, and feeds on flowers and grass seeds, particularly Guinea grass.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn = np.dot(vects, query_vector)\n",
    "top_n = np.argpartition(-nn, 10)[:10]\n",
    "top_n = top_n[nn[top_n].argsort()[::-1]]\n",
    "\n",
    "for idx in top_n:\n",
    "    print(idx, nn[idx], sentences[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1332c7-8ee6-482e-bda8-915fb0df8795",
   "metadata": {},
   "source": [
    "## Select a set of random vectors as reference points\n",
    "\n",
    "We ensure we sample *randomly* otherwise the similarity below (summing similarities) won't work, as we'll be summing correlated similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbb29811-bf51-48ff-8a2b-8334cf84d8be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.11857848e-02, -5.44647865e-02,  3.62523698e-04,  2.95326742e-02,\n",
       "       -5.78769393e-02, -7.91969908e-03,  3.07337733e-02,  4.14794946e-02,\n",
       "       -5.60921808e-02, -5.84231076e-03, -3.03641039e-02,  9.00863878e-02,\n",
       "        3.40140830e-02,  2.63503545e-02, -1.00795820e-01,  3.90036975e-02,\n",
       "       -7.67220630e-02, -5.09445686e-02,  1.63975372e-02,  8.20156256e-02,\n",
       "       -9.47527599e-03, -5.44015110e-02,  1.07057850e-01,  7.64754614e-02,\n",
       "       -1.70995573e-02, -3.54264228e-02,  1.39781900e-02, -9.59667981e-02,\n",
       "        2.48580918e-02, -3.75828426e-02,  4.13216111e-02, -5.19822618e-02,\n",
       "       -9.73467119e-03,  5.07475979e-02,  1.21104619e-02, -7.02523766e-02,\n",
       "        4.40860425e-02, -8.25177776e-03, -3.68595383e-02, -2.36404814e-02,\n",
       "        1.92492737e-02, -9.24268809e-02,  2.44768352e-02,  2.25758189e-02,\n",
       "        2.02920451e-02,  7.23337102e-03,  4.41314485e-02, -3.62581152e-03,\n",
       "        8.41175403e-02,  1.97563163e-02,  1.81072349e-01,  1.15561081e-01,\n",
       "       -1.01793971e-01, -4.90034156e-02,  5.31890595e-02, -5.53284026e-02,\n",
       "       -9.03957268e-02,  2.94963615e-03, -1.50936097e-02,  8.85338349e-02,\n",
       "       -7.41456986e-02, -4.27682949e-04, -4.66229074e-02, -1.09944203e-02,\n",
       "        3.65794161e-02, -5.00368031e-02,  3.28870359e-02, -1.02039650e-02,\n",
       "       -3.30684532e-02, -3.33624793e-02,  3.09513560e-02,  5.66565043e-02,\n",
       "       -3.44277880e-02,  1.16641984e-01, -1.28603308e-02,  6.38101909e-02,\n",
       "       -4.67027182e-02, -7.02506694e-03,  2.05610787e-02, -1.18704359e-02,\n",
       "        2.02258470e-02, -5.00796949e-02,  7.56212069e-02, -4.02929130e-02,\n",
       "        6.51926892e-02,  1.13240846e-01,  3.80288396e-03,  1.48359531e-02,\n",
       "        3.42859191e-03,  1.28192004e-01,  5.18490269e-02, -2.49151951e-02,\n",
       "       -3.85143109e-03,  1.94597007e-02, -2.07850496e-03,  4.59681356e-04,\n",
       "        3.05068715e-02, -4.46794764e-02,  2.04016157e-02,  4.04866748e-02,\n",
       "        7.05131864e-02, -6.97722323e-02,  2.30114056e-02,  5.35083817e-02,\n",
       "       -5.91992271e-02, -4.60074191e-02, -3.84423911e-02, -7.36667299e-02,\n",
       "       -7.18183097e-02, -2.40183637e-03, -4.97382568e-02,  1.90223302e-02,\n",
       "       -6.36159397e-03,  6.94728037e-02,  3.89271960e-02, -1.16028248e-02,\n",
       "       -4.71645796e-02, -7.33171448e-02, -3.15089302e-02,  3.33563547e-02,\n",
       "        5.51379842e-02, -4.23043802e-02, -5.32947925e-02,  2.34761080e-02,\n",
       "        8.92330870e-05,  4.20044988e-02, -4.80250736e-02,  6.14677592e-03,\n",
       "        6.24399502e-02,  6.01134905e-02,  9.03420749e-02,  3.21097752e-02,\n",
       "        3.55400546e-03,  3.78249567e-02,  6.49025244e-02, -7.84488850e-02,\n",
       "        2.74142190e-02, -1.56397667e-03, -4.31229391e-02,  1.79053546e-03,\n",
       "       -5.23364945e-02,  1.10866109e-02, -2.48746611e-02, -4.44718181e-02,\n",
       "       -4.04109935e-02,  2.95166990e-02,  1.05175435e-02, -8.94191345e-02,\n",
       "        2.77649071e-02,  1.18098418e-02,  3.55286100e-02, -1.91869915e-02,\n",
       "        7.52079106e-02, -8.47246962e-02, -1.42208120e-02, -2.58785538e-02,\n",
       "       -1.54958752e-02, -6.59759320e-02, -6.95485533e-02,  6.65055975e-02,\n",
       "       -1.08728875e-01, -2.08110512e-02, -1.50310182e-02, -5.83422233e-02,\n",
       "        3.47549923e-02,  6.75786303e-02, -4.27174177e-02,  1.08843003e-02,\n",
       "        7.68000050e-02,  5.54031478e-02,  7.91207661e-02, -3.13899576e-03,\n",
       "        7.10520400e-02, -3.25849222e-02, -8.57849150e-02,  6.77862678e-02,\n",
       "       -4.72876298e-02,  3.06193080e-02, -9.32556285e-02,  7.78981854e-03,\n",
       "       -1.94327984e-02, -1.57383478e-02,  4.37386134e-02,  4.39297936e-02,\n",
       "        2.01897082e-02,  1.92279488e-02,  1.21635423e-02, -7.18552917e-03,\n",
       "        4.03071948e-02, -2.79081085e-03, -7.12434482e-02,  9.99965672e-02,\n",
       "       -5.37912112e-03, -6.63444329e-02,  3.13573798e-02, -3.91563935e-02,\n",
       "        1.72292126e-02, -2.27984937e-02,  6.55572230e-02, -5.94492797e-02,\n",
       "        3.47076636e-02, -1.01084106e-02,  3.60655566e-02,  6.34758482e-02,\n",
       "       -2.74485163e-02, -1.05986799e-01, -7.02876901e-02, -4.11691330e-02,\n",
       "        3.43423503e-04, -4.70645917e-02,  3.51841244e-02,  1.30646474e-02,\n",
       "        9.45594996e-02,  4.37243585e-02, -4.91582846e-02, -6.72819767e-02,\n",
       "        1.10318968e-01, -2.60597385e-02,  4.91992046e-02, -2.50633590e-03,\n",
       "       -2.82769874e-02,  3.46995136e-02, -7.06528465e-02, -1.85213822e-02,\n",
       "       -7.74261900e-02, -5.71060828e-02,  8.17257589e-03,  7.01171052e-02,\n",
       "       -2.95126549e-02,  1.96392024e-02, -5.91305924e-03,  4.18586045e-02,\n",
       "        1.02277616e-01,  1.95731310e-02,  6.44142322e-02,  9.94382337e-03,\n",
       "       -2.27212326e-02,  3.42455730e-02, -7.29871034e-02,  2.90704049e-03,\n",
       "        9.63270438e-04, -1.49307447e-02, -3.90685743e-02,  2.26129578e-02,\n",
       "        8.88878340e-02,  6.29461202e-02, -1.85263697e-02,  1.95755174e-02,\n",
       "       -4.80704246e-02, -2.85207474e-02, -8.38488576e-03, -3.16873075e-02,\n",
       "        2.56849540e-02, -3.28933057e-02, -2.92499301e-02, -1.47713382e-02,\n",
       "        7.22490008e-02, -1.85378201e-02, -1.86834807e-02,  7.71505983e-03,\n",
       "        1.15531907e-01,  3.40986528e-02,  5.23893193e-02,  6.46747500e-02,\n",
       "        3.45666831e-02,  7.34940479e-02, -5.42321545e-02,  4.15922529e-03,\n",
       "       -3.23534472e-02,  1.93210337e-02, -8.65789954e-02, -3.93331008e-02,\n",
       "        7.55059999e-02,  1.47470566e-02,  1.76728413e-02, -6.95130027e-02,\n",
       "       -3.55916177e-02, -1.90042573e-03, -4.72033440e-02, -1.23432333e-01,\n",
       "       -4.31162876e-03, -1.09054906e-02,  7.36419353e-02,  9.71896864e-03,\n",
       "       -1.13778035e-03, -3.89070949e-02, -2.17503233e-02, -4.91178202e-02,\n",
       "        3.68262277e-02,  7.19906999e-02, -2.55896598e-02,  6.90016772e-02,\n",
       "       -6.39569119e-03, -4.39843809e-03,  4.18711630e-02,  1.93047613e-02,\n",
       "        8.85883439e-02, -3.71620970e-02,  2.71483759e-02, -5.87911673e-03,\n",
       "       -7.96010650e-02, -4.12334136e-02, -1.07441084e-02, -8.67985450e-02,\n",
       "       -3.57024408e-02,  4.19011459e-02, -1.15880431e-01,  3.06387061e-03,\n",
       "       -8.81201748e-02,  7.63377457e-02, -2.25038017e-03,  2.14463990e-02,\n",
       "       -3.80428825e-02,  6.03707991e-02,  9.28453326e-04,  2.02578293e-03,\n",
       "        4.57728680e-02,  2.64193716e-02, -8.50281290e-02,  7.38663952e-03,\n",
       "        9.09483929e-02,  2.79598242e-02,  1.28081235e-02, -3.57256958e-03,\n",
       "       -7.34290960e-02,  2.72571539e-02,  4.79563905e-02,  2.22680875e-02,\n",
       "        7.09181155e-02,  3.44344581e-02,  1.16550933e-03,  1.12557360e-02,\n",
       "        1.97928706e-02,  3.25082454e-02, -5.28743595e-02, -7.48306797e-03,\n",
       "        1.04727125e-02, -1.21350682e-02,  5.15909772e-02,  2.82848141e-02,\n",
       "       -1.77591450e-02,  1.31822061e-02, -2.20489055e-02, -8.12244535e-03,\n",
       "       -3.01380160e-02,  2.24654215e-02,  3.57413337e-02, -6.38803918e-02,\n",
       "        3.12554048e-02, -4.69942954e-02,  1.01807701e-01, -3.89100622e-02,\n",
       "        1.02790927e-01, -4.94737253e-02,  1.63625100e-02, -5.48782539e-02,\n",
       "        4.56311771e-02,  5.69711606e-02,  2.87470735e-02,  8.51190942e-02,\n",
       "        1.24589121e-02,  2.57543459e-02,  5.88643652e-02, -6.34143984e-02,\n",
       "        1.76008911e-02, -7.30866459e-02,  1.93195433e-02, -1.36026127e-02,\n",
       "        7.60834920e-02, -1.09835498e-01, -1.55026768e-01,  1.43963414e-02,\n",
       "       -1.40571697e-02,  2.62241621e-02,  2.79969556e-02, -1.30177092e-02,\n",
       "       -5.33166250e-02, -1.12065270e-02, -3.45226888e-02,  3.37975330e-02,\n",
       "        2.99731035e-02,  3.40023173e-02, -4.06430259e-02,  4.08632071e-02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vectors = len(vects)\n",
    "\n",
    "def centroid():\n",
    "    \"\"\" Sample a unit vector from a sphere in N dimensions.\n",
    "    It's actually important this is gaussian\n",
    "    https://stackoverflow.com/questions/59954810/generate-random-points-on-10-dimensional-unit-sphere\n",
    "    IE Don't do this\n",
    "        projection = np.random.random_sample(size=num_dims)\n",
    "        projection /= np.linalg.norm(projection)\n",
    "    \"\"\"\n",
    "    num_dims = len(vects[0])\n",
    "    projection = np.random.normal(size=num_dims)\n",
    "    projection /= np.linalg.norm(projection)\n",
    "    return projection   \n",
    "\n",
    "centroid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3114e48c-90ba-4e04-8555-45449f2b5f61",
   "metadata": {},
   "source": [
    "## Most similar vectors to centroid\n",
    "\n",
    "Get most similar vectors, with a specified floor in specificity. The top 10 here should correspond to the top 10 ground truth above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "494f7e0a-d5a5-42c6-8154-e476c69f48a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.05252691),\n",
       " (2, 0.04499867),\n",
       " (5, 0.07958562),\n",
       " (6, 0.049663156),\n",
       " (7, 0.056482542),\n",
       " (14, 0.12559442),\n",
       " (15, 0.0227612),\n",
       " (16, 0.044335753),\n",
       " (19, 0.029843405),\n",
       " (20, 0.105600625)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_similar(centroid, floor):\n",
    "\n",
    "    nn = np.dot(vects, centroid)\n",
    "    idx_above_thresh = np.argwhere(nn >= floor)[: ,0]\n",
    "    return list(zip(idx_above_thresh, nn[idx_above_thresh]))\n",
    "\n",
    "nn_above_thresh = most_similar(query_vector, 0.01)\n",
    "nn_above_thresh[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf2f93-b5b7-4835-ab89-cc8e62bbd54b",
   "metadata": {},
   "source": [
    "## Create a compressed index based on shared reference points\n",
    "\n",
    "As mentioned in [this blog article](https://softwaredoug.com/blog/2023/03/02/shared-dot-product.html) we can use shared reference points between query and vector to estimate their similarity. Below we store\n",
    "\n",
    "- A table of these reference vectors (`refs`) that can stand in for the full vector space\n",
    "- A mapping of these `refs` -> a set of indexed vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49e68ba0-04f7-454c-80c8-6083bebccca6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 77040 0.009786802933246103 8.181861333083361\n",
      "10 107692 0.1339900213736967 38.28956733306404\n",
      "20 173499 0.22692831713103379 68.17820320802275\n",
      "30 67792 0.28654232023704795 98.14517087501008\n",
      "40 44995 0.36756584400694886 128.37458304106258\n",
      "50 212794 0.4404342068071889 158.73485320806503\n",
      "60 66141 0.4978383030618694 188.78089770802762\n",
      "70 27423 0.5365798909401568 218.9450416660402\n",
      "80 79451 0.580765578503079 248.67051737499423\n",
      "90 47747 0.6177246064286236 278.14855766599067\n",
      "100 36658 0.669014364521569 308.11617233301513\n",
      "110 15962 0.7033388064394216 338.0380136250751\n",
      "120 195579 0.7469898022377276 368.2472629999975\n",
      "130 25330 0.7620763927043601 398.0715541250538\n",
      "140 134988 0.7834939165949446 428.5510214160895\n",
      "150 58647 0.8042700390316095 458.83546000008937\n",
      "160 229317 0.8206488330215674 489.0020875830669\n",
      "170 49632 0.8307516998917024 519.2349730830174\n",
      "180 37701 0.8460094069672535 549.425390999997\n",
      "190 131710 0.8615008590765165 579.7196220000042\n",
      "200 95865 0.872802431456492 610.0885791659821\n",
      "210 29688 0.8855496660558384 640.6546626660274\n",
      "220 64855 0.894269880237429 671.0452085409779\n",
      "230 17201 0.903282656817193 701.5540646660374\n",
      "240 23696 0.9155425838353876 732.2803080000449\n",
      "250 31710 0.922220577820264 762.8285333330277\n",
      "260 122122 0.9294656575825809 793.215062082978\n",
      "270 33886 0.9345318271175997 823.7654137910577\n",
      "280 34506 0.9402918637037789 854.6053938330151\n",
      "290 40344 0.9455003128245356 885.7939030410489\n",
      "300 26226 0.9499244457289129 916.3593981250888\n",
      "310 42322 0.9532532798937985 947.2909857080085\n",
      "320 95834 0.9578510701139825 978.0047480000649\n",
      "330 123496 0.9615960720671509 1009.0677709160373\n",
      "340 52033 0.9644772336783402 1039.7208665830549\n",
      "350 29314 0.9673106300000318 1070.5358824580908\n",
      "360 17450 0.9700883848408723 1101.2791437080596\n",
      "370 11439 0.972360411975622 1132.0822921660729\n",
      "380 32883 0.9757276108145189 1162.9177860830678\n",
      "390 32265 0.9773352430980109 1193.8904671660857\n",
      "400 59599 0.9790229076484805 1224.6807528750505\n",
      "410 81802 0.9805742632743996 1255.377639916027\n",
      "420 99841 0.9826568807106357 1286.575430875062\n",
      "430 76866 0.9841266796454443 1317.296303250012\n",
      "440 27592 0.9859636107255941 1348.255641708034\n",
      "450 57802 0.9868968123656204 1379.08823570807\n",
      "460 48504 0.9877621771317324 1409.8922870830866\n",
      "470 59959 0.9888229222575451 1441.012045999989\n",
      "480 74506 0.9894605126511323 1471.7697910830611\n",
      "490 140280 0.9908031492061878 1503.1899162910413\n",
      "500 18972 0.9914557297704154 1534.2879203750053\n",
      "510 62368 0.9922004109593392 1566.723286124994\n",
      "520 39122 0.9928136105668 1597.6230923330877\n",
      "530 19439 0.9933998786812461 1628.6501201250358\n",
      "540 83108 0.9939960555525561 1659.3207647909876\n",
      "550 44093 0.9944153992244492 1689.7707709580427\n",
      "560 125539 0.9949361171011805 1720.4827036660863\n",
      "570 91483 0.9953995420375834 1751.500418166048\n",
      "580 54802 0.9958366706576938 1782.3682828330202\n",
      "590 31117 0.9961630244574797 1813.526389666018\n",
      "600 8365 0.9965343487691863 1844.4281345410272\n",
      "610 79990 0.9967969308260791 1876.6533102500252\n",
      "620 84565 0.9971002912285271 1907.7273271250306\n",
      "630 33705 0.9973126943243784 1938.5647865830688\n",
      "640 46937 0.9975934424355216 1969.3178703329759\n",
      "650 163676 0.9979078549129331 2000.4219381660223\n",
      "660 251651 0.9980754145322083 2031.0966470410349\n",
      "670 27762 0.998194700720608 2062.335128708044\n",
      "680 166380 0.9983716609553693 2093.215739166015\n",
      "690 164815 0.9985157190359287 2124.131113625015\n",
      "700 78774 0.9986023571408155 2155.110602041008\n",
      "710 71504 0.9987207540818044 2186.0166349579813\n",
      "720 79559 0.9988527438046451 2217.029071249999\n",
      "730 74616 0.9989415415103867 2247.704705583048\n",
      "740 76318 0.9990281796152735 2278.6642100410536\n",
      "750 61101 0.9991271401485678 2309.310364041012\n",
      "760 69590 0.9991928174216271 2340.061964666005\n",
      "770 60545 0.9992675142041394 2370.460667125066\n",
      "780 34580 0.9993349699720204 2401.50669454108\n",
      "790 38599 0.9994238947131066 2432.8631915830774\n",
      "800 35416 0.9994670867302055 2463.69016175007\n",
      "810 28628 0.99950265662664 2494.345433957991\n",
      "820 75845 0.9995627443445453 2525.562423916068\n",
      "830 31696 0.9995901839789375 2556.3431751660537\n",
      "840 71690 0.9996191480374628 2587.1130240830826\n",
      "850 48406 0.9996540827571752 2617.937975000008\n",
      "860 139216 0.9996892715475764 2649.170057750074\n",
      "870 27612 0.9997183626414459 2680.056977665983\n",
      "880 63058 0.9997454211698049 2711.2478717500344\n",
      "890 100250 0.9997611735525116 2742.150471166009\n",
      "900 108674 0.9997850561972604 2774.1378964160103\n",
      "910 80877 0.9998070333118432 2805.8998425410828\n",
      "920 52403 0.999824056047994 2837.236887832987\n",
      "930 55851 0.9998418409962112 2868.2921007910045\n",
      "940 42099 0.9998661047469932 2899.5800025410717\n",
      "950 28573 0.9998793164228117 2930.443131832988\n",
      "960 53934 0.9998879548262315 2961.613390124985\n",
      "970 12884 0.9999028179615274 2992.6183025410865\n",
      "980 124399 0.9999119645063248 3023.716727333027\n",
      "990 39430 0.9999197136623337 3054.549318833044\n",
      "1000 89970 0.9999249221114545 3085.233902000007\n",
      "1010 63406 0.9999321631260858 3116.274166707997\n",
      "1020 46741 0.9999395311760615 3147.1795412499923\n",
      "1030 62232 0.9999446125898378 3177.9720266660443\n",
      "1040 35809 0.9999502021449918 3209.0889154580655\n",
      "1050 229401 0.9999551565234237 3240.362120958045\n",
      "1060 48041 0.999960492007889 3271.683875333052\n",
      "1070 16335 0.9999625245733994 3302.491390125011\n",
      "1080 66214 0.999967351916487 3333.709178958088\n",
      "1090 27392 0.999971417047508 3364.916766625014\n",
      "1100 116108 0.9999759903199068 3396.0998374160845\n",
      "1110 83624 0.9999782769561061 3427.2654859999893\n",
      "1120 84756 0.9999795473095502 3458.0185477910563\n",
      "1130 37128 0.9999815798750608 3489.7160482500913\n",
      "1140 97649 0.9999829772638492 3520.693568375078\n",
      "1150 63039 0.9999837394759157 3552.0820191660896\n",
      "1160 62238 0.9999851368647041 3582.937973916065\n",
      "1170 34521 0.9999866612888371 3614.9497594580753\n",
      "1180 134955 0.9999871694302147 3645.745814875001\n",
      "1190 73685 0.999988820889692 3677.269173250068\n",
      "1200 65427 0.9999895831017585 3712.7869621249847\n",
      "1210 103547 0.9999900912431361 3743.6944716660073\n",
      "1220 74349 0.999991615667269 3774.485851458041\n",
      "1230 44775 0.999992250843991 3805.2654552080203\n",
      "1240 87328 0.9999927589853687 3836.115619958029\n",
      "1250 160929 0.9999932671267463 3866.450714583043\n",
      "1260 22103 0.9999937752681239 3897.34682337509\n",
      "1270 34963 0.9999945374801904 3928.277861041017\n",
      "1280 99786 0.999995045621568 3959.3554046250647\n",
      "1290 41762 0.9999954267276013 3990.4955731660593\n",
      "1300 70910 0.9999960619043233 4021.386491207988\n",
      "1310 159781 0.9999966970810453 4052.6182386250002\n",
      "1320 79905 0.9999968241163898 4083.7271788329817\n",
      "1330 132567 0.9999970781870786 4114.464447375038\n",
      "1340 96277 0.9999970781870786 4145.375578875071\n",
      "1350 82471 0.9999977133638006 4176.7364297080785\n",
      "1360 249073 0.9999980944698339 4208.092806915985\n",
      "1370 118272 0.9999983485405227 4239.209238582989\n",
      "1380 36525 0.9999983485405227 4271.740106208017\n",
      "1390 204326 0.9999984755758671 4303.48203045805\n",
      "1400 132565 0.9999986026112115 4336.946070041042\n",
      "1410 49096 0.9999986026112115 4368.749325541081\n",
      "1420 62721 0.9999986026112115 4399.874567583087\n",
      "1430 79458 0.9999986026112115 4432.511313499999\n",
      "1440 147378 0.9999988566819004 4464.255877875024\n",
      "1450 71894 0.9999988566819004 4495.390858375002\n",
      "1460 36484 0.9999989837172447 4526.560433958075\n",
      "1470 101912 0.9999989837172447 4558.049375790986\n",
      "1480 40499 0.9999991107525892 4592.91731925006\n",
      "1490 106752 0.9999991107525892 4624.794394083088\n",
      "1500 72160 0.9999991107525892 4656.958749875077\n",
      "1510 32953 0.9999992377879335 4693.376550291083\n",
      "1520 157137 0.9999992377879335 4726.740973583073\n",
      "1530 57308 0.9999992377879335 4758.818191958009\n",
      "1540 15265 0.999999364823278 4790.571555541013\n",
      "1550 43357 0.9999994918586224 4822.895579250064\n",
      "1560 33293 0.9999996188939668 4856.20794762508\n",
      "1570 57151 0.9999996188939668 4889.131829291\n",
      "1580 34820 0.9999998729646556 4926.958329125075\n",
      "1590 55698 1.0 4958.89015641599\n",
      "1600 76777 1.0 4991.597978833015\n",
      "1610 36228 1.0 5024.925813790993\n",
      "1620 36933 1.0 5061.816119541065\n",
      "1630 41113 1.0 5095.927688250085\n",
      "1640 22502 1.0 5128.152094374993\n",
      "1650 55370 1.0 5163.123798041022\n",
      "1660 71268 1.0 5198.794149000081\n",
      "1670 51053 1.0 5236.924652375048\n",
      "1680 49773 1.0 5277.8134442080045\n",
      "1690 43859 1.0 5311.622756458004\n",
      "1700 56587 1.0 5345.129633291042\n",
      "1710 50669 1.0 5378.095308208023\n",
      "1720 124240 1.0 5410.2674297500635\n",
      "1730 49747 1.0 5442.492320166086\n",
      "1740 46569 1.0 5475.136461624992\n",
      "1750 41016 1.0 5507.35627412505\n",
      "1760 54242 1.0 5540.329734083032\n",
      "1770 65991 1.0 5572.691364791011\n",
      "1780 70693 1.0 5604.325926457997\n",
      "1790 49097 1.0 5636.4801654580515\n",
      "1800 82562 1.0 5671.107592916\n",
      "1810 41822 1.0 5707.019929207978\n",
      "1820 91188 1.0 5739.096532540978\n",
      "1830 42004 1.0 5771.596820665989\n",
      "1840 95020 1.0 5804.767738791066\n",
      "1850 63777 1.0 5837.313566582976\n",
      "1860 84272 1.0 5871.024907250074\n",
      "1870 42450 1.0 5905.74994679098\n",
      "1880 45616 1.0 5939.3692486250075\n",
      "1890 93978 1.0 5972.46314883302\n",
      "1900 112211 1.0 6006.655619375058\n",
      "1910 49644 1.0 6043.148191665998\n",
      "1920 94222 1.0 6078.248444708064\n",
      "1930 69077 1.0 6121.428043375025\n",
      "1940 27513 1.0 6168.055149874999\n",
      "1950 65164 1.0 6223.762662333087\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m specificity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.12\u001b[39m\n\u001b[1;32m     16\u001b[0m center \u001b[38;5;241m=\u001b[39m centroid()    \n\u001b[0;32m---> 17\u001b[0m top_n \u001b[38;5;241m=\u001b[39m \u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecificity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m refs[ref_ord, :] \u001b[38;5;241m=\u001b[39m center\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# idx = []\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mmost_similar\u001b[0;34m(centroid, floor)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmost_similar\u001b[39m(centroid, floor):\n\u001b[0;32m----> 3\u001b[0m     nn \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     idx_above_thresh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margwhere(nn \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m floor)[: ,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(idx_above_thresh, nn[idx_above_thresh]))\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ref_neighbors = {}   # reference pts -> neighbors\n",
    "ref_weights = {}     # (ref_ord, vect_ord) -> float\n",
    "from time import perf_counter\n",
    "from pyroaring import BitMap\n",
    "\n",
    "num_refs = 4000\n",
    "refs = np.zeros( (num_refs, vects.shape[1]) )\n",
    "\n",
    "all_indexed_vectors = BitMap()\n",
    "\n",
    "start = perf_counter()\n",
    "\n",
    "for ref_ord in range(0, num_refs):\n",
    "    specificity = 0.12\n",
    "    \n",
    "    center = centroid()    \n",
    "    top_n = most_similar(center, specificity)\n",
    "    \n",
    "    refs[ref_ord, :] = center\n",
    "    # idx = []\n",
    "    bit_set = BitMap()\n",
    "    for vector_ord, dot_prod in top_n:\n",
    "        all_indexed_vectors.add(vector_ord)\n",
    "        bit_set.add(vector_ord)\n",
    "        ref_weights[(ref_ord,vector_ord)] = dot_prod\n",
    "    ref_neighbors[ref_ord] = bit_set\n",
    "    \n",
    "    if ref_ord % 10 == 0:\n",
    "        print(ref_ord, len(ref_neighbors[ref_ord]), len(all_indexed_vectors) / len(vects), perf_counter() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd73f9-a2e2-4859-968a-4a709f96a180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = np.dot(refs, query_vector)\n",
    "nn[nn > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c1bdc-d1b6-433c-a85c-2a1120bb8b5b",
   "metadata": {},
   "source": [
    "# Search time!\n",
    "\n",
    "Now when we search we go through the following steps, using just our reference points.\n",
    "\n",
    "## Similarity to reference points\n",
    "\n",
    "Compute similarity to `refs` from above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941af46-79c7-4bf3-805b-08bf2e886a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query vect -> refs similarity\n",
    "nn = np.dot(refs, query_vector)\n",
    "\n",
    "top_n_ref_points = np.argpartition(-nn, 10)[:10]\n",
    "scored = nn[top_n_ref_points]\n",
    "\n",
    "scored, top_n_ref_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c22529-96ef-4aee-8123-c7ede47dea94",
   "metadata": {},
   "source": [
    "## Using reference points, As, estimate q.v\n",
    "\n",
    "We have query vector `q`, which is similar to a set of reference points `A`, can we estimate `q.v`. We expect `q.v` to [approach `q.A*v.A` as we implement below](https://softwaredoug.com/blog/2023/03/02/shared-dot-product.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c66f3750-255e-4d49-99f6-686f35d9f262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(167639, [0.03348637198213025, 0.0215893165539961]),\n",
       " (181097, [0.03135131881147713]),\n",
       " (140960,\n",
       "  [0.03068362407891349,\n",
       "   0.01968200334702778,\n",
       "   0.016470234480528256,\n",
       "   0.021633394397366064]),\n",
       " (466857, [0.03044927361617932]),\n",
       " (451401, [0.030388548659453448, 0.01595256260519746]),\n",
       " (135071, [0.030258985871415626]),\n",
       " (608179, [0.029679072046431887, 0.01760330514900589]),\n",
       " (186829, [0.029606397626255852]),\n",
       " (227331, [0.029441571079467137]),\n",
       " (512583, [0.02939986434101547, 0.01587321875023174])]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = {}\n",
    "cutoff = 0.0\n",
    "for ref_ord, ref_score in zip(top_n_ref_points, scored):\n",
    "    ref = refs[ref_ordinal]\n",
    "\n",
    "    for vect_id, score in ref_neighbors[ref_ord]:\n",
    "        # print(vect_id, score, score*ref_score)\n",
    "        combined = score * ref_score\n",
    "        if combined > cutoff:\n",
    "            try:\n",
    "                candidates[vect_id].append(combined)\n",
    "            except KeyError:\n",
    "                candidates[vect_id] = [combined]\n",
    "            \n",
    "list(candidates.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4f402-c454-4296-9f3d-cd84c615ed09",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sum the shared candidates\n",
    "\n",
    "Should we sum the shared reference points?\n",
    "\n",
    "Out of N reference points A0...AN we observe `u.A0...u.AN` and `v.0...vN`. We assume `u.v` would correlate to the dot product of these `u.A0*v.A0 + u.A1*v.A1 + ... + u.AN*v.AN`.\n",
    "\n",
    "Note this only applies because we generate the reference points *randomly* introducing some bias in the reference points would create a case where many terms of the summation correlated heavily (the similarit yof `ref` `A0` and `A1` were so similar, that it was double counting). For example if `A0` and `A1` both occured towards the center of the data, we would be biased towards more general responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2a264261-2603-451a-b846-5cde37eeaa35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summed_candidates = {}\n",
    "for vect_id, scored in candidates.items():\n",
    "    summed_candidates[vect_id] = sum(scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8d181b23-2d50-4d5f-a8d4-1611d2946616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZF --  100 10 in the UK Singles chart, however it was a bigger hit for Amazulu in 1986 from their album Amazulu.\n",
      "\n",
      "0 (100, 0.2527549925590207) 10 in the UK Singles chart, however it was a bigger hit for Amazulu in 1986 from their album Amazulu.\n",
      "\n",
      "1 (321056, 0.16217920551009507) It made 1 on the Dutch charts in 1986.\n",
      "\n",
      "2 (323155, 0.15819849527952193) It peaked at #49 in the Australian singles chart.\n",
      "\n",
      "3 (334214, 0.1571568908150194) It was a chart hit in Japan peaking at #40 and selling over 11,000 copies.\n",
      "\n",
      "4 (321057, 0.154641193353647) It made #60 on the UK Singles Chart.\n",
      "\n",
      "5 (323296, 0.1536705427431023) It peaked at number 86 on the UK Singles Chart.\n",
      "\n",
      "6 (350317, 0.15308964160221297) It was released in July 1991 on the Festival Records label and spent nine weeks in the top 50 and peaked at No.34 on the Australian singles charts.\n",
      "\n",
      "7 (323205, 0.15230754549290793) It peaked at number 14 in the United States, while peaking at number 11 in Canada.\n",
      "\n",
      "8 (324573, 0.1521790017468438) It reached number 14 in the UK Singles Chart, number 61 in Germany and number 31 in Australia.\n",
      "\n",
      "9 (282544, 0.1518405095444498) It also peaked at number 14 in Australia, their highest charting single to date in the country.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = summed_candidates.items()\n",
    "results = sorted(results,\n",
    "                 key=lambda scored: scored[1],\n",
    "                 reverse=True)[:10]\n",
    "# 21340\n",
    "print(\"ZF -- \", query, sentences[query])\n",
    "rank = -1\n",
    "for idx, result in enumerate(results):\n",
    "    print(idx, result, sentences[result[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9d8d1-52fb-4a68-a15e-2cb1b902d97e",
   "metadata": {},
   "source": [
    "## Putting search together\n",
    "\n",
    "Let's put the code above into one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f7497fd6-18ed-4b17-9c31-d8280a6327ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (646834, 0.3755975662324765) The only remaining structure of the original town is the Meers Store & Restaurant, which Food Network named as the best hamburger joint in Oklahoma & one of the best in the United States of America, largely due to its signature MeersBurger.\n",
      "\n",
      "1 (668904, 0.28697694511992144) The restaurant is famous for its burgers and has been featured on Season 1 of the Travel Channel's Man vs. Food.\n",
      "\n",
      "2 (644077, 0.27009526247083593) The Northbound side has a McDonald's (open 24 hours) and a KFC, with the Southbound side having a Burger King and a KFC.\n",
      "\n",
      "3 (11317, 0.26373954450629955) Additionally, the chain also offers unique burgers in each city where its restaurants are located.\n",
      "\n",
      "4 (77913, 0.25635830953768185) Bobby's Burger Palace features an array of burgers inspired by Chef Bobby Flay.\n",
      "\n",
      "5 (697338, 0.2505928149242444) The stretch between Scott Street and Market Street is a popular restaurant area.\n",
      "\n",
      "6 (324149, 0.24802131059412347) It provides information and reviews on restaurants, including images of menus where the restaurant does not have its own website.\n",
      "\n",
      "7 (456646, 0.23135125126329925) Plankton is the arch-rival of Mr. Krabs, who owns the far more profitable Krusty Krab restaurant and sells a fictional burger called the Krabby Patty.\n",
      "\n",
      "8 (557522, 0.22776547319367638) The BK Whopper Bar is a limited service concept created by fast-food restaurant Burger King in 2009.\n",
      "\n",
      "9 (450946, 0.22637349787853273) Paynes Bay also has many restaurants.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _search(query_vector, at=10):\n",
    "    \n",
    "    # query vect -> refs similarity\n",
    "    nn = np.dot(refs, query_vector)\n",
    "\n",
    "    top_n_ref_points = np.argpartition(-nn, 30)[:30]\n",
    "    scored = nn[top_n_ref_points]\n",
    "\n",
    "    # Candidates via our index\n",
    "    candidates = {}\n",
    "    cutoff = 0.0\n",
    "    for ref_ord, ref_score in zip(top_n_ref_points, scored):\n",
    "        ref = refs[ref_ordinal]\n",
    "\n",
    "        for vect_id, score in ref_neighbors[ref_ord]:\n",
    "            # print(vect_id, score, score*ref_score)\n",
    "            combined = score * ref_score\n",
    "            if combined > cutoff:\n",
    "                try:\n",
    "                    candidates[vect_id].append(combined)\n",
    "                except KeyError:\n",
    "                    candidates[vect_id] = [combined]\n",
    "                    \n",
    "    summed_candidates = {}\n",
    "    for vect_id, scored in candidates.items():\n",
    "        summed_candidates[vect_id] = sum(scored)\n",
    "        \n",
    "    results = summed_candidates.items()\n",
    "    return sorted(results,\n",
    "                  key=lambda scored: scored[1],\n",
    "                  reverse=True)[:at]\n",
    "\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def search(query, at=10):\n",
    "    query_vector = model.encode(query)\n",
    "    return _search(query_vector, at)\n",
    "\n",
    "def search_ground_truth(query, at=10):\n",
    "    query_vector = model.encode(query)\n",
    "    nn = np.dot(vects, query_vector)\n",
    "    top_n = np.argpartition(-nn, at)[:at]\n",
    "    top_n = top_n[nn[top_n].argsort()[::-1]]\n",
    "    return sorted(zip(top_n, nn[top_n]),\n",
    "                  key=lambda scored: scored[1],\n",
    "                  reverse=True)\n",
    "query = \"best hamburger restaurants\"\n",
    "retrieved = set()\n",
    "at=10\n",
    "results = search(query, at=at)\n",
    "retrieved = set()\n",
    "for idx, result in enumerate(results[:10]):\n",
    "    retrieved.add(result[0])\n",
    "    print(idx, result, sentences[result[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f5fd8225-c1aa-4218-a1b2-2dcb98a14f64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (646834, 0.68789977) The only remaining structure of the original town is the Meers Store & Restaurant, which Food Network named as the best hamburger joint in Oklahoma & one of the best in the United States of America, largely due to its signature MeersBurger.\n",
      "\n",
      "1 (307125, 0.59501857) It is known for its small, square hamburgers.\n",
      "\n",
      "2 (11317, 0.59236324) Additionally, the chain also offers unique burgers in each city where its restaurants are located.\n",
      "\n",
      "3 (653355, 0.58579004) The place serves American foods, such as burgers, hotdogs, chicken, etc.\n",
      "\n",
      "4 (174575, 0.57885575) Hamburgers are grilled-to-order in full view of the customers and are served wrapped in paper on paper plates.\n",
      "\n",
      "5 (331556, 0.57167995) Its tagline is The Last Great Hamburger Stand.\n",
      "\n",
      "6 (331002, 0.5645297) Its restaurant network includes global chains like Burger King, Domino's Pizza, Kentucky Fried Chicken, Little Caesars Pizza, McDonald's, Pizza Hut, Pizza Pizza, Carl's Jr., Popeyes, Sampi, Papa John's and Subway.\n",
      "\n",
      "7 (470450, 0.56435025) Ray's Hell Burger was a hamburger restaurant in Arlington, Virginia, United States.\n",
      "\n",
      "8 (668898, 0.55298215) The restaurant has an extensive menu ranging from complete breakfasts to hamburgers, milkshakes, pizza, chicken, ribs, salads and a number of sandwiches, including Montreal-style smoked meat.\n",
      "\n",
      "9 (53043, 0.5508517) As of March 2018, he has worked as the assistant coach of Hamburger SV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = search_ground_truth(query, at)\n",
    "rank = -1\n",
    "ground_truth = set()\n",
    "for idx, result in enumerate(results):\n",
    "    ground_truth.add(result[0])\n",
    "    print(idx, result, sentences[result[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "941d3c04-48de-45fd-8e4f-7d9be602e647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "best buy electronics -- 0.1\n",
      "GT -  The device started shipping by August 2014, and eventually became widely available through Best Buy and Amazon, generating around $5 million in total retail sales.\n",
      "RT -  ATR broke the Guinness Book of World Records for the Most Consumer Electronics Recycled in One Week (Multiple Locations) on April 25, 2015 during the OMPC.\n",
      "-------\n",
      "hamburger restaurant -- 0.3\n",
      "GT -  It is known for its small, square hamburgers.\n",
      "RT -  It is known for its small, square hamburgers.\n",
      "-------\n",
      "coffee shops in seattle -- 0.3\n",
      "GT -  Hudsons Coffee is an Australian chain of coffee retailers.\n",
      "RT -  Six of the eleven stores are located in Seattle (in the Fremont, Green Lake, Columbia City, View Ridge, and West Seattle neighborhoods).\n",
      "-------\n",
      "ai chatbot -- 0.3\n",
      "GT -  He is currently CEO and co-founder of marketing-tech company Botworx.ai an artificial intelligence (AI) and natural language processing company that aims to help businesses interact with their customers via AI-powered chatbots.\n",
      "RT -  The term \"ChatterBot\" was originally coined by Michael Mauldin (creator of the first Verbot, Julia) in 1994 to describe these conversational programs.\n",
      "-------\n",
      "endangered species of africa -- 0.4\n",
      "GT -  Species are found in Africa.\n",
      "RT -  Species are found in Africa.\n",
      "-------\n",
      "what is the capital of france? -- 0.1\n",
      "GT -  It is known from France.\n",
      "RT -  Its county seat is the town of Paris.\n",
      "-------\n",
      "breaking bad main character -- 0.0\n",
      "GT -  For the Breaking Bad character, see Jesse Pinkman.\n",
      "RT -  The following is a list of characters from The Walking Dead television series based on the eponymous comic book series.\n",
      "-------\n",
      "what are underwear gnomes? -- 0.2\n",
      "GT -  The title is also a synonym for \"underwear\".\n",
      "RT -  Sometimes they are accompanied by Devils which lay two lit candles on their horns and prod them with hot skewers.\n",
      "-------\n",
      "funny reddit stories -- 0.2\n",
      "GT -  These are collected short stories.\n",
      "RT -  These are collected short stories.\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\"best buy electronics\",\n",
    "                \"hamburger restaurant\",\n",
    "                \"coffee shops in seattle\",\n",
    "                \"ai chatbot\",\n",
    "                \"endangered species of africa\",\n",
    "                \"what is the capital of france?\",\n",
    "                \"breaking bad main character\",\n",
    "                \"what are underwear gnomes?\",\n",
    "                \"funny reddit stories\"]\n",
    "at = 10\n",
    "for query in test_queries:\n",
    "    gt_results = search_ground_truth(query, at=at)\n",
    "    retrieved_results = search(query, at=at)\n",
    "    \n",
    "    retrieved = set([result[0] for result in retrieved_results])\n",
    "    ground_truth = set([result[0] for result in gt_results])\n",
    "    \n",
    "    print('-------')\n",
    "    print(query, '--', len(ground_truth & retrieved) / len(ground_truth))\n",
    "    print('GT - ', sentences[gt_results[0][0]].strip())\n",
    "    print('RT - ', sentences[retrieved_results[0][0]].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "892c35c4-896d-41b9-bfd6-03dc4b3afb81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2483, 96611)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_lengths = [len(ref_neighbors[idx]) for idx in range(len(ref_neighbors))]\n",
    "min(ref_lengths), max(ref_lengths)                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca55be8-089f-40da-b268-1fcd111de991",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "This is just a toy prototype of course, and would need to be evaluated for recall.\n",
    "\n",
    "* Consider how you'd treat the reference points in a traditional search index (like Solr, Elasticsearch etc)\n",
    "* Benchmark with more data (8m -> 80m wikipedia sentences)?\n",
    "* Study the relationship of needed reference points to get good recall\n",
    "* Test and ensure increasing reference points increases recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94cf913-6101-410d-857d-504c3bd002f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
